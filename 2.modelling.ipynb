{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard library imports\n",
    "import os\n",
    "import multiprocessing\n",
    "\n",
    "# Third-party library imports\n",
    "import fiona\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import rasterio as rio\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A. Dataset Preparation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Load Data\n",
    "\n",
    "In this step, we will prepare the dataset that will be used for analysis. This process involves several important steps:\n",
    "\n",
    "1. **Loading Shapefile**: We use the `load_shapefile_with_fiona` function. There are 4 shapefiles that will be loaded:\n",
    "\n",
    "   - `gdf_training`: Training dataset that already have UHI Index value and some raster value\n",
    "   - `gdf_additional`: Additional dataset from interpolation of gdf_training data that already have UHI Index value and some raster value\n",
    "   - `gdf_testing`: Submission template that will be used for inference and already have some raster value\n",
    "   - `gdf_evaluation`: Highest score from previous submission and already have UHI Index value with some raster value\n",
    "\n",
    "2. **Converting Coordinates**: After loading the data, we convert the coordinate system of the additional dataset (`gdf_additional`) to EPSG:4326, which is a commonly used geographic coordinate system.\n",
    "\n",
    "3. **Adding Longitude and Latitude Columns**: From the centroid geometry of each feature in `gdf_additional`, we extract the longitude and latitude values, which will be used for mapping the other raster value to data.\n",
    "\n",
    "4. **Dropping Geometry Column**: After extracting the necessary information, we remove the geometry column from all DataFrames (`df_training`, `df_additional`, `df_testing`, and `df_evaluation`) to simplify the dataset and focus on the relevant attributes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING DATASET\n",
    "\n",
    "# Function to load shp using Fiona lib\n",
    "def load_shapefile_with_fiona(filepath, encoding='latin1'):\n",
    "    # Open the shapefile with Fiona to capture all attributes\n",
    "    with fiona.open(filepath, encoding=encoding) as src:\n",
    "        features = list(src)\n",
    "        gdf = gpd.GeoDataFrame.from_features(features, crs=src.crs)\n",
    "    return gdf\n",
    "\n",
    "# Loading the data using Fiona\n",
    "gdf_training = load_shapefile_with_fiona('https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/modelling_data/Vector_AR_Dataset_Training_49ft.shp')\n",
    "gdf_additional = load_shapefile_with_fiona('https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/modelling_data/Vector_AR_Dataset_TrainingAdditional_49ft.shp')\n",
    "gdf_testing = load_shapefile_with_fiona('https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/modelling_data/Vector_AR_Dataset_Testing_49ft.shp')\n",
    "gdf_evaluation = load_shapefile_with_fiona('https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/modelling_data/Vector_AR_ReferencedSHP_49ft.shp')\n",
    "\n",
    "gdf_additional = gdf_additional.to_crs(\"EPSG:4326\")\n",
    "\n",
    "# Buat kolom Longitude dan Latitude dari centroid geometry\n",
    "gdf_additional[\"Longitude\"] = gdf_additional[\"geometry\"].centroid.x\n",
    "gdf_additional[\"Latitude\"] = gdf_additional[\"geometry\"].centroid.y\n",
    "\n",
    "# Drop the geometry column\n",
    "df_training = gdf_training.drop(columns='geometry')\n",
    "df_additional = gdf_additional.drop(columns='geometry')\n",
    "df_testing = gdf_testing.drop(columns='geometry')\n",
    "df_evaluation = gdf_evaluation.drop(columns='geometry')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Mapping Additional Raster Value to Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset already have raster value but we will add more raster value to the dataset to improve the model performance. Some of the raster data are sentinel3, sentinel1, sentinel2, topography, landsat, and some special indices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameter\n",
    "LANDSAT_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/landsat_highres.tif\"\n",
    "S1_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s1_highres.tif\"\n",
    "BUILDING_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/building.tif\"\n",
    "SAMPLE_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/sample.geojson\"\n",
    "TOPO_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/topography.tif\"\n",
    "S3_SLSTR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s3_slstr_highres.tif\"\n",
    "S3_LAND = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s3_land_highres.tif\"\n",
    "S3_WATER = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s3_water_highres.tif\"\n",
    "S3_AEROSOL = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s3_aerosol.tif\"\n",
    "S3_SR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s3_sr.tif\"\n",
    "TEST_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/data/Submission_template_UHI2025-v2.csv\"\n",
    "S1_DOWNSCALE_DIR = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/s1_downscale.tif\"\n",
    "SPECIAL_INDICES = \"https://storage.googleapis.com/gee-ramiqcom-s4g-bucket/ey_uhi/special_indices.tif\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section of the code is extracting raster data from various additional sources and mapping it to the datasets. The following steps are performed:\n",
    "\n",
    "1. **Define Indices and Bands**: Various indices (e.g., NDMI, NBR) and bands for different satellite data (Sentinel-1, Sentinel-2, Landsat) are defined.\n",
    "\n",
    "2. **Extract Raster Data**: A function `extract_raster_data` is created to sample raster values based on the coordinates (Longitude and Latitude) from the datasets.\n",
    "\n",
    "3. **Process Each Dataset**: For each dataset (training, additional, testing, evaluation):\n",
    "   - Raster data is extracted from Landsat, Sentinel-1, and other sources.\n",
    "   - New indices are calculated based on the extracted bands.\n",
    "   - The geometry column is dropped if present, and rows with NoData values are filtered out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample sentinel-2, sentinel-1, special indices\n",
    "label = \"UHI Index\"\n",
    "\n",
    "# Load images and its indices\n",
    "ms_indices = [\n",
    "    dict(name=\"NDMI\", band1=\"NIR\", band2=\"SWIR1\", cmap=\"RdYlGn\"),\n",
    "    dict(name=\"NBR\", band1=\"NIR\", band2=\"SWIR2\", cmap=\"RdYlGn\"),\n",
    "    dict(name=\"NBR2\", band1=\"SWIR1\", band2=\"SWIR2\", cmap=\"RdYlGn\"),\n",
    "    dict(name=\"NDWI\", band1=\"GREEN\", band2=\"NIR\", cmap=\"RdBu\"),\n",
    "    dict(name=\"MNDWI\", band1=\"GREEN\", band2=\"SWIR1\", cmap=\"RdBu\"),\n",
    "    dict(name=\"MNDWI2\", band1=\"GREEN\", band2=\"SWIR2\", cmap=\"RdBu\"),\n",
    "    dict(name=\"NDVI\", band1=\"NIR\", band2=\"RED\", cmap=\"RdYlGn\"),\n",
    "    dict(name=\"NDTI\", band1=\"GREEN\", band2=\"RED\", cmap=\"RdYlGn\"),\n",
    "]\n",
    "landsat_band_map = dict(BLUE=1, GREEN=2, RED=3, NIR=4, SWIR1=5, SWIR2=6)\n",
    "s1_indices = [\n",
    "    dict(name=\"RVI\", band1=\"VV\", band2=\"VH\", cmap=\"RdYlGn\"),\n",
    "]\n",
    "s1_band_map = dict(VV=0, VH=1)\n",
    "\n",
    "bands_s1 = [\"VV\", \"VH\"]\n",
    "bands_topo = [\"elevation\", \"slope\", \"aspect\"]\n",
    "bands_landsat = [\"COASTAL\", \"BLUE\", \"GREEN\", \"RED\", \"NIR\", \"SWIR1\", \"SWIR2\", \"LST\"]\n",
    "bands_s3_lst = [\"S3_SLSTR\"]\n",
    "bands_special = [\"Dryness\", \"Greeness\", \"Wetness\", \"Hotness\", \"TPI\"]\n",
    "s3_land_bands = [\"IWV\", \"OGVI\", \"OTCI\", \"RC681\", \"RC865\"]\n",
    "s3_water_bands = [\"IWV_Water\", \"PAR\", \"KD490_M07\", \"A865\", \"T865\", \"CHL_NN\"]\n",
    "bands_l_indices_ness = [ms_indices[i][\"name\"]+\"_ness\" for i in range(len(ms_indices))]\n",
    "\n",
    "\n",
    "datasets = [df_training, df_additional, df_testing, df_evaluation]\n",
    "\n",
    "# Fungsi untuk ekstraksi data dari raster\n",
    "def extract_raster_data(source, df, bands):\n",
    "    coords = [(x, y) for x, y in zip(df[\"Longitude\"], df[\"Latitude\"])]\n",
    "    df[bands] = list(source.sample(coords))\n",
    "\n",
    "# Proses ekstraksi untuk setiap dataset\n",
    "for df in datasets:\n",
    "    with rio.open(LANDSAT_DIR) as source:\n",
    "        extract_raster_data(source, df, bands_landsat)\n",
    "\n",
    "        # Also indices\n",
    "        for props in ms_indices:\n",
    "            name = props[\"name\"]\n",
    "            band1 = props[\"band1\"]\n",
    "            band2 = props[\"band2\"]\n",
    "\n",
    "            df[name] = (df[band1] - df[band2]) / (df[band1] + df[band2])\n",
    "\n",
    "    with rio.open(S1_DOWNSCALE_DIR) as source:\n",
    "        extract_raster_data(source, df, bands_s1)\n",
    "\n",
    "        for props in s1_indices:\n",
    "            name = props[\"name\"]\n",
    "            band1 = props[\"band1\"]\n",
    "            band2 = props[\"band2\"]\n",
    "\n",
    "            df[name] = (df[band1] - df[band2]) / (df[band1] + df[band2])\n",
    "\n",
    "    with rio.open(SPECIAL_INDICES) as source:\n",
    "        extract_raster_data(source, df, bands_special)\n",
    "\n",
    "    with rio.open(TOPO_DIR) as source:\n",
    "        extract_raster_data(source, df, bands_topo)\n",
    "\n",
    "    with rio.open(S3_SLSTR) as source:\n",
    "        extract_raster_data(source, df, bands_s3_lst)\n",
    "\n",
    "    with rio.open(S3_LAND) as source:\n",
    "        extract_raster_data(source, df, s3_land_bands)\n",
    "\n",
    "    with rio.open(S3_WATER) as source:\n",
    "        extract_raster_data(source, df, s3_water_bands)\n",
    "\n",
    "    # Filter NoData\n",
    "    df = df[df[\"BLUE\"] >= 0]\n",
    "\n",
    "    # Drop geometry column if there is any\n",
    "    df = df[df.columns[3:]]\n",
    "    if \"geometry\" in df.columns:\n",
    "        del df[\"geometry\"]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Cleaning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we perform data cleaning on the datasets. The following steps are taken:\n",
    "\n",
    "1. **Eliminate Unused Columns**: We remove columns that are not needed for the analysis, specifically the \"Longitude\", \"Latitude\", and \"datetime\" columns from all datasets (`df_training`, `df_additional`, `df_testing`, and `df_evaluation`). This helps to simplify the datasets and focus on the relevant features.\n",
    "\n",
    "2. **Renaming Columns**: The columns of the datasets are renamed to a new set of descriptive names. This makes it easier to understand the data and ensures consistency across the datasets.\n",
    "\n",
    "3. **Convert Columns to Numeric**: The first 26 columns of the new column names are converted to numeric types, coercing any errors to NaN. This is important for ensuring that the data can be used in mathematical operations and modeling.\n",
    "\n",
    "4. **Combine Datasets**: The training and additional datasets are combined into a single DataFrame (`df_combined`) using row binding. This allows for a more comprehensive analysis and modeling.\n",
    "\n",
    "5. **Eliminate Rows with Null Values**: Any rows with null values in the combined dataset are removed to ensure that the analysis is performed on complete data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Eliminate unused columns\n",
    "cols_to_remove = [\"Longitude\", \"Latitude\", \"datetime\"]\n",
    "df_training = df_training.drop(columns=cols_to_remove, errors='ignore')\n",
    "df_additional = df_additional.drop(columns=cols_to_remove, errors='ignore')\n",
    "df_testing = df_testing.drop(columns=cols_to_remove, errors='ignore')\n",
    "df_evaluation = df_evaluation.drop(columns=cols_to_remove, errors='ignore')\n",
    "\n",
    "# Renaming columns\n",
    "new_columns = ['Y_IndexUHI', 'X_Mult_Blue', 'X_Mult_Green', 'X_Mult_Red', 'X_Mult_Nir', 'X_Mult_NDVI', 'X_Mult_NDWI',\n",
    "               'X_DEM_Elevation', 'X_DEM_Aspect', 'X_DEM_Slope', 'X_DEM_Radiation', 'X_Thermal_L8B10', 'X_Thermal_TSharp_Rlm',\n",
    "               'X_Thermal_TSharp_Svm', 'X_Thermal_NonTSharp_Rlm', 'X_Thermal_NonTSharp_Svm', 'X_Bool_Park', 'X_Proxy_Park',\n",
    "               'X_Proxy_Water', 'X_Proxy_Tree', 'X_Proxy_Road', 'X_Proxy_Rail', 'X_Proxy_Impe', 'X_Proxy_GrasShrub',\n",
    "               'X_Proxy_Building', 'X_Proxy_Soil', 'COASTAL', 'BLUE', 'GREEN',\n",
    "       'RED', 'NIR', 'SWIR1', 'SWIR2', 'LST', 'NDMI', 'NBR', 'NBR2', 'NDWI',\n",
    "       'MNDWI', 'MNDWI2', 'NDVI', 'NDTI', 'VV', 'VH', 'RVI', 'Dryness',\n",
    "       'Greeness', 'Wetness', 'Hotness', 'TPI', 'elevation', 'slope', 'aspect',\n",
    "       'S3_SLSTR', 'IWV', 'OGVI', 'OTCI', 'RC681', 'RC865', 'IWV_Water', 'PAR',\n",
    "       'KD490_M07', 'A865', 'T865', 'CHL_NN']\n",
    "\n",
    "df_training.columns = new_columns\n",
    "df_additional.columns = new_columns\n",
    "df_testing.columns = new_columns\n",
    "df_evaluation.columns = new_columns\n",
    "\n",
    "# Convert the first 26 columns to numeric (coercing errors to NaN)\n",
    "for col in new_columns[:26]:\n",
    "    df_training[col] = pd.to_numeric(df_training[col], errors='coerce')\n",
    "    df_additional[col] = pd.to_numeric(df_additional[col], errors='coerce')\n",
    "    df_testing[col] = pd.to_numeric(df_testing[col], errors='coerce')\n",
    "    df_evaluation[col] = pd.to_numeric(df_evaluation[col], errors='coerce')\n",
    "\n",
    "# Combine the training and additional datasets (row binding)\n",
    "df_combined = pd.concat([df_training, df_additional], ignore_index=True)\n",
    "\n",
    "# Eliminate rows with null values\n",
    "df_combined = df_combined.dropna()\n",
    "\n",
    "# View the resulting DataFrame\n",
    "print(df_combined.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B. Model Development\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Explanatory Data Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we compute the correlation matrix for the combined dataset to understand the relationships between different features.\n",
    "\n",
    "1. **Compute Correlation Matrix**: The correlation matrix is calculated using the combined dataset (training and additional), which helps identify how features are related to each other.\n",
    "\n",
    "2. **Visualize with Heatmap**: A heatmap is created using Matplotlib to visually represent the correlation values. The 'coolwarm' colormap is used for better clarity.\n",
    "\n",
    "3. **Add Colorbar and Annotations**: A colorbar is added to indicate the scale of correlation values, and text annotations are included in each cell of the heatmap to display the exact correlation coefficients.\n",
    "\n",
    "4. **Adjust Layout**: The layout is adjusted for better presentation, and a title is added to the heatmap.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## EXPLANATORY DATA ANALYSIS\n",
    "\n",
    "# Compute the correlation matrix for the combined dataset\n",
    "corr_matrix = df_combined.corr()\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "fig, ax = plt.subplots(figsize=(12, 10))\n",
    "\n",
    "# Create a heatmap using imshow with a 'coolwarm' colormap\n",
    "cax = ax.imshow(corr_matrix, interpolation='nearest', cmap='coolwarm')\n",
    "\n",
    "# Add a colorbar to show the scale\n",
    "fig.colorbar(cax)\n",
    "\n",
    "# Set tick positions and labels with variable names\n",
    "ax.set_xticks(np.arange(len(corr_matrix.columns)))\n",
    "ax.set_yticks(np.arange(len(corr_matrix.columns)))\n",
    "ax.set_xticklabels(corr_matrix.columns, rotation=90)\n",
    "ax.set_yticklabels(corr_matrix.columns)\n",
    "\n",
    "# Add text annotations in each cell with the correlation value\n",
    "for i in range(len(corr_matrix.index)):\n",
    "    for j in range(len(corr_matrix.columns)):\n",
    "        value = corr_matrix.iloc[i, j]\n",
    "        ax.text(j, i, f\"{value:.2f}\", ha=\"center\", va=\"center\", color=\"black\", fontsize=8)\n",
    "\n",
    "# Add a title and adjust layout\n",
    "ax.set_title(\"Correlation Matrix Heatmap\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hyperparameter Tuning\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section focuses on optimizing the hyperparameters of the Random Forest model using Grid Search.\n",
    "\n",
    "1. **Define Predictors and Response**: The predictors (features) and response (target variable which is UHI Index) are defined based on the previously established column names.\n",
    "\n",
    "2. **Create Feature Matrices and Target Vectors**: Feature matrices and target vectors are created for both training and evaluation datasets.\n",
    "\n",
    "3. **Combine Datasets**: The training and evaluation datasets are combined to facilitate hyperparameter tuning.\n",
    "\n",
    "4. **Predefined Split**: A `PredefinedSplit` is created to differentiate between training and evaluation samples, ensuring that the grid search trains on the combined dataset and validates on the evaluation dataset.\n",
    "\n",
    "5. **Parameter Grid Definition**: A parameter grid is defined for the Random Forest model, specifying different values for `n_estimators` (number of trees) and `max_features` (number of features to consider).\n",
    "\n",
    "6. **Grid Search Setup**: A `GridSearchCV` instance is created to perform cross-validation and find the best hyperparameters based on the R² scoring metric.\n",
    "\n",
    "7. **Model Fitting**: The grid search is executed to fit the model and identify the best parameters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define predictors and response using the new_columns from earlier steps.\n",
    "# Response is the first column and predictors are the rest.\n",
    "predictors = new_columns[1:]\n",
    "response = new_columns[0]\n",
    "\n",
    "# Create feature matrices and target vectors for training and evaluation data\n",
    "X_train = df_combined[predictors]\n",
    "y_train = df_combined[response]\n",
    "\n",
    "X_eval = df_evaluation[predictors]\n",
    "y_eval = df_evaluation[response]\n",
    "\n",
    "# Combine training and evaluation data\n",
    "X_all = pd.concat([X_train, X_eval], axis=0)\n",
    "y_all = pd.concat([y_train, y_eval], axis=0)\n",
    "\n",
    "# Create a PredefinedSplit: assign -1 to training samples and 0 to evaluation samples.\n",
    "# This ensures that grid search always trains on df_combined and validates on df_testing.\n",
    "test_fold = [-1] * len(X_train) + [0] * len(X_eval)\n",
    "ps = PredefinedSplit(test_fold=test_fold)\n",
    "\n",
    "# Parameter grid for RandomForest:\n",
    "# 'n_estimators' corresponds to the number of trees and 'max_features' to mtry.\n",
    "param_grid = {\n",
    "    'n_estimators': [10, 50, 100, 500, 1000],\n",
    "    'max_features': [1, 10, 20, 26]\n",
    "}\n",
    "\n",
    "# Determine the number of cores to use\n",
    "n_jobs = multiprocessing.cpu_count() - 5 if multiprocessing.cpu_count() > 5 else 1\n",
    "print(\"Number of workers:\", n_jobs)\n",
    "\n",
    "# Create the RandomForestRegressor model\n",
    "model_reg = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV with our PredefinedSplit\n",
    "grid_search = GridSearchCV(estimator=model_reg,\n",
    "                           param_grid=param_grid,\n",
    "                           scoring='r2',\n",
    "                           cv=ps,\n",
    "                        #    n_jobs=n_jobs,\n",
    "                           refit=False)\n",
    "grid_search.fit(X_all, y_all)\n",
    "\n",
    "# print details\n",
    "print(\"Best parameters found:\", grid_search.best_params_)\n",
    "print(\"Best CV R^2 score:\", grid_search.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Training and Evaluation for Baseline Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we fit the Random Forest model using the training data.\n",
    "\n",
    "1. **Best Parameters Retrieval**: The best hyperparameters obtained from the grid search are retrieved.\n",
    "\n",
    "2. **Model Initialization**: A `RandomForestRegressor` model is initialized with the retrieved best parameters and a fixed random state for reproducibility.\n",
    "\n",
    "3. **Model Training**: The model is trained on the training dataset (`X_train` and `y_train`).\n",
    "4. **Model Evaluation**: The model's performance is evaluated on both the training and evaluation datasets:\n",
    "   - Predictions are made on the training data, and the R² score is calculated to assess how well the model fits the training data.\n",
    "   - Predictions are also made on the evaluation data, with the R² score calculated to evaluate the model's generalization performance.\n",
    "\n",
    "This process ensures that the model is properly trained and evaluated, providing insights into its predictive capabilities.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL FITTING\n",
    "# Fit the model on the training data only.\n",
    "best_params = grid_search.best_params_\n",
    "model_reg_best = RandomForestRegressor( random_state=42, **best_params)\n",
    "model_reg_best.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training and evaluation dataset\n",
    "x_pred_train = model_reg_best.predict(X_train)\n",
    "eval_r2 = r2_score(y_train, x_pred_train)\n",
    "print(\"Evaluation R^2 on training data:\", eval_r2)\n",
    "\n",
    "y_pred_eval = model_reg_best.predict(X_eval)\n",
    "eval_r2 = r2_score(y_eval, y_pred_eval)\n",
    "print(\"Evaluation R^2 on evaluation data:\", eval_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL EVALUATION\n",
    "# Function to make 1:1 plot\n",
    "def plot_1to1(observed, predicted, dataset_label=\"\", ax=None):\n",
    "    \"\"\"\n",
    "    Create a 1:1 scatterplot comparing observed and predicted values,\n",
    "    compute evaluation metrics, and annotate the plot with R², MAE, and MAPE.\n",
    "\n",
    "    Parameters:\n",
    "      observed (array-like): Observed values.\n",
    "      predicted (array-like): Predicted values.\n",
    "      dataset_label (str): Label to include in the title (e.g., \"Training Data\" or \"Evaluation Data\").\n",
    "      ax (matplotlib.axes.Axes): Optional axis to plot on.\n",
    "\n",
    "    Returns:\n",
    "      ax: The axis with the plot.\n",
    "    \"\"\"\n",
    "    # Compute evaluation metrics\n",
    "    r2 = r2_score(observed, predicted)\n",
    "    mae = mean_absolute_error(observed, predicted)\n",
    "    mape = np.mean(np.abs((observed - predicted) / observed)) * 100\n",
    "\n",
    "    # Format metrics for annotation\n",
    "    r2_label = f\"R² = {r2:.2f}\"\n",
    "    mae_label = f\"MAE = {mae:.4f}\"\n",
    "    mape_label = f\"MAPE = {mape:.2f}%\"\n",
    "\n",
    "    # Determine common limits for both observed and predicted\n",
    "    all_vals = np.concatenate([observed, predicted])\n",
    "    x_lim_min = np.nanmin(all_vals)\n",
    "    x_lim_max = np.nanmax(all_vals)\n",
    "\n",
    "    # Set annotation coordinates as fractions of the range\n",
    "    ann_x = x_lim_min + 0.1 * (x_lim_max - x_lim_min)\n",
    "    ann_y = x_lim_max - 0.1 * (x_lim_max - x_lim_min)\n",
    "\n",
    "    # If no axis provided, create one\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "\n",
    "    # Create scatter plot: points colored by the observed value using the \"magma\" colormap\n",
    "    sc = ax.scatter(observed, predicted, c=observed, cmap=\"magma\", alpha=0.3, s=20)\n",
    "    plt.colorbar(sc, ax=ax, label=\"Observed Value\")\n",
    "\n",
    "    # Plot 1:1 reference line\n",
    "    ax.plot([x_lim_min, x_lim_max], [x_lim_min, x_lim_max], color=\"lightgray\",\n",
    "            linewidth=0.8, linestyle=\"solid\", label=\"1:1 Reference Line\")\n",
    "\n",
    "    # Compute linear regression fit (predicted ~ observed) and plot the fitted line\n",
    "    slope, intercept = np.polyfit(observed, predicted, 1)\n",
    "    x_vals = np.array([x_lim_min, x_lim_max])\n",
    "    y_vals = slope * x_vals + intercept\n",
    "    ax.plot(x_vals, y_vals, color=\"white\", linewidth=1, linestyle=\"dashed\", label=\"Linear Fit\")\n",
    "\n",
    "    # Set labels and title\n",
    "    ax.set_xlabel(\"Observed UHI Index (Unitless)\")\n",
    "    ax.set_ylabel(\"Predicted UHI Index (Unitless)\")\n",
    "    ax.set_title(f\"1:1 Scatterplot: {dataset_label}\")\n",
    "\n",
    "    # Annotate with metrics\n",
    "    ax.text(ann_x, ann_y, f\"{r2_label}\\n{mae_label}\\n{mape_label}\",\n",
    "            color=\"black\", fontsize=10, ha=\"left\", va=\"top\")\n",
    "\n",
    "    # Set fixed aspect ratio and limits\n",
    "    ax.set_xlim(x_lim_min, x_lim_max)\n",
    "    ax.set_ylim(x_lim_min, x_lim_max)\n",
    "    ax.set_aspect('equal', adjustable='box')\n",
    "\n",
    "    ax.legend(loc=\"lower right\")\n",
    "\n",
    "    return ax\n",
    "\n",
    "# Generate predictions for both datasets\n",
    "y_train_pred = model_reg_best.predict(X_train)\n",
    "y_eval_pred = model_reg_best.predict(X_eval)\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot training data\n",
    "plot_1to1(y_train.values, y_train_pred, dataset_label=\"Training Data\", ax=ax1)\n",
    "\n",
    "# Plot evaluation data\n",
    "plot_1to1(y_eval.values, y_eval_pred, dataset_label=\"Evaluation Data\", ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL INFERENCE WITHOUT FEATURE SELECTION\n",
    "# Load submission template\n",
    "submission_template = pd.read_csv(TEST_DIR)\n",
    "\n",
    "# Generate predictions using the fitted model\n",
    "predicted_uhi = model_reg_best.predict(df_testing.iloc[:, 1:])\n",
    "\n",
    "# Add predictions to the submission template in the \"UHI Index\" column.\n",
    "submission_template['UHI Index'] = predicted_uhi\n",
    "\n",
    "# Export the submission file to CSV without row indices.\n",
    "submission_template.to_csv('./Submission_XGB_49ft_NO_FEATAURE_SELECTION.csv', index=False)\n",
    "\n",
    "# Print\n",
    "print(\"Done inferencing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# C. Feature Selection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## FEATURE SELECTION\n",
    "# Import required libs\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "# Use RFECV with the trained model (model_reg_best) as the estimator.\n",
    "# RFECV will fit the model on the training data and evaluate on the eval data at each step.\n",
    "rfecv = RFECV(estimator=model_reg_best, step=1, cv=ps, scoring='r2')\n",
    "rfecv.fit(X_all, y_all)\n",
    "\n",
    "# Output the optimal number of features and the selected feature names\n",
    "optimal_features = [feature for feature, selected in zip(predictors, rfecv.support_) if selected]\n",
    "print(\"Optimal number of features:\", rfecv.n_features_)\n",
    "print(\"Selected features:\", optimal_features)\n",
    "\n",
    "# Optionally, view the ranking of all features (lower rank means more important)\n",
    "ranking_dict = dict(zip(predictors, rfecv.ranking_))\n",
    "print(\"Feature ranking:\", ranking_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# D. Model training & evaluation (optimized model)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Model Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL REFITTING\n",
    "# Subset the training and evaluation data to only include the selected features\n",
    "X_train_selected = X_train[optimal_features]\n",
    "X_eval_selected = X_eval[optimal_features]\n",
    "\n",
    "# Create and train a new RandomForestRegressor using only the selected features\n",
    "model_reg_final = RandomForestRegressor(random_state=42, **best_params)\n",
    "model_reg_final.fit(X_train_selected, y_train)\n",
    "\n",
    "# Evaluate the new model on training data\n",
    "train_predictions = model_reg_final.predict(X_train_selected)\n",
    "train_r2 = r2_score(y_train, train_predictions)\n",
    "print(\"Training R² with selected features:\", train_r2)\n",
    "\n",
    "# Evaluate the new model on evaluation data\n",
    "eval_predictions = model_reg_final.predict(X_eval_selected)\n",
    "eval_r2 = r2_score(y_eval, eval_predictions)\n",
    "print(\"Evaluation R² with selected features:\", eval_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Model Evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL REEVALUATION\n",
    "# Generate predictions for both datasets\n",
    "y_train_pred_selected = model_reg_final.predict(X_train[optimal_features])\n",
    "y_eval_pred_selected = model_reg_final.predict(X_eval[optimal_features])\n",
    "\n",
    "# Create subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 6))\n",
    "\n",
    "# Plot training data\n",
    "plot_1to1(y_train.values, y_train_pred_selected, dataset_label=\"Training Data\", ax=ax1)\n",
    "\n",
    "# Plot evaluation data\n",
    "plot_1to1(y_eval.values, y_eval_pred_selected, dataset_label=\"Evaluation Data\", ax=ax2)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Model Tuning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL RETUNING\n",
    "# Combine the selected training and evaluation data\n",
    "X_all_selected = pd.concat([X_train_selected, X_eval_selected], axis=0)\n",
    "y_all_selected = pd.concat([y_train, y_eval], axis=0)\n",
    "\n",
    "# Create a PredefinedSplit for retuning: training samples get -1 and evaluation samples get 0\n",
    "test_fold_selected = [-1] * len(X_train_selected) + [0] * len(X_eval_selected)\n",
    "ps_selected = PredefinedSplit(test_fold=test_fold_selected)\n",
    "\n",
    "# Define an expanded parameter grid\n",
    "param_grid_final = {\n",
    "    'n_estimators': [100, 200, 500, 1500],\n",
    "    'max_features': [1, 2, 3, 4, 5],            # since we now have only 5 features, try values between 1 and 5\n",
    "    'max_depth': [None, 5, 10, 15, 20],\n",
    "    'min_samples_split': [1, 2, 5, 10]\n",
    "}\n",
    "\n",
    "# Create a new RandomForestRegressor instance for retuning\n",
    "model_reg_retest = RandomForestRegressor(random_state=42)\n",
    "\n",
    "# Set up GridSearchCV using the new parameter grid and the predefined split\n",
    "grid_search_final = GridSearchCV(estimator=model_reg_retest,\n",
    "                                 param_grid=param_grid_final,\n",
    "                                 scoring='r2',\n",
    "                                 cv=ps_selected,\n",
    "                                #  n_jobs=n_jobs,\n",
    "                                 refit=False)\n",
    "\n",
    "grid_search_final.fit(X_all_selected, y_all_selected)\n",
    "\n",
    "print(\"Best parameters after retuning:\", grid_search_final.best_params_)\n",
    "print(\"Best CV R² score after retuning:\", grid_search_final.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Refitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL REFITTING\n",
    "# Fit the model on the training data only.\n",
    "best_params_refit = grid_search_final.best_params_\n",
    "model_reg_refit = RandomForestRegressor(random_state=42, **best_params_refit)\n",
    "model_reg_refit.fit(X_all_selected, y_all_selected)\n",
    "\n",
    "# Evaluate the model on the training and evaluation dataset\n",
    "x_pred_train_refit = model_reg_refit.predict(X_train_selected)\n",
    "eval_r2 = r2_score(y_train, x_pred_train_refit)\n",
    "print(\"Evaluation R^2 on training data:\", eval_r2)\n",
    "\n",
    "y_pred_eval_refit = model_reg_refit.predict(X_eval_selected)\n",
    "eval_r2 = r2_score(y_eval, y_pred_eval_refit)\n",
    "print(\"Evaluation R^2 on evaluation data:\", eval_r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Model Inference\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL INFERENCE\n",
    "# Load submission template\n",
    "submission_template = pd.read_csv(TEST_DIR)\n",
    "\n",
    "# Generate predictions using the fitted model\n",
    "predicted_uhi = model_reg_refit.predict(df_testing[optimal_features])\n",
    "\n",
    "# Add predictions to the submission template in the \"UHI Index\" column.\n",
    "submission_template['UHI Index'] = predicted_uhi\n",
    "\n",
    "# Export the submission file to CSV without row indices.\n",
    "submission_template.to_csv('./Submission_XGB_49ft_FEATURESELECTION.csv', index=False)\n",
    "\n",
    "# Print\n",
    "print(\"Done inferencing!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# E. Saving Final Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MODEL SAVING\n",
    "# Import required libs\n",
    "import joblib\n",
    "\n",
    "# Define export directory and filename\n",
    "export_dir = \"./Model\"\n",
    "os.makedirs(export_dir, exist_ok=True)\n",
    "model_filename = os.path.join(export_dir, \"09797_Model_RandomForest.pkl\")\n",
    "\n",
    "# Export the model\n",
    "joblib.dump(model_reg_refit, model_filename)\n",
    "print(\"Model exported to:\", model_filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
